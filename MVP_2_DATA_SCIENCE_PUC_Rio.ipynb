{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxdiHWoqV1oPjulVZqvFoc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabioPojo1987/FabioPojo1987-MVP_2_DATA_SCIENCE_PUC_RIO/blob/main/MVP_2_DATA_SCIENCE_PUC_Rio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Projeto de MVP da 2ª Sprint do curso de Ciência de Dados na PUC-Rio (por Fabio Pojo de Almeida).**\n",
        "\n",
        "\n",
        "Este projeto se trata na construção de um modelo de aprendizado de máquina (\"machine learning\") para criar insights sobre como ocorre a variação de dados dos valores das ações do Google no Mercado de Ações.\n",
        "\n",
        "Onde foi utilizado um recorte temporal compreendido entre os anos de 2010 e 2023\n",
        "\n",
        "Este projeto está baseado em um modelo de \"Rede Neural Recorrente\" e está usando de referência os dados presentes nas planilhas csv\n",
        "\n",
        "Para isso, foi decidido um exemplo onde esses dados foram separados em duas bases em 2 arquivos diferentes: 1- base de treino e 2- teste (a faixa da base de teste tem como referência um período de 3 semanas, ou 21 dias)\n",
        "\n",
        "- A base de dados utilizada para os valores das ações do Google (Alphabet.inc.) foi obtida através do Kaggle em: https://www.kaggle.com/datasets/alirezajavid1999/google-stock-2010-2023/download?datasetVersionNumber=1\n",
        "\n",
        "\n",
        "Campos do dataset :\n",
        "\n",
        "1.   Date\n",
        "2.   Open - Valor das ações na Abertura\n",
        "3.   High - Valor mais alto do dia (\"Pico\")\n",
        "4.   Low - Valor mais baixo (\"vale\")\n",
        "5.   Volume - Volume a ser Negociado\n",
        "6.   High - Close : Valor (a maior) no momento de fechamento\n",
        "\n",
        "\n",
        "Objetivo - Usar os dados de treino para prever os valores que estão nos dados de teste, o objetivo é comparar a previsão do modelo com o que de fato aconteceu.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3uFgPvZiVsmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar as bibliotecas\n",
        "import numpy as np # vai ser usado pra criar os arrays\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import plotly.express as px\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt # para gerar graficos\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.layers import GRU, Dropout, SimpleRNN, LSTM, Dense, SimpleRNN, GRU\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "dl1yGzrdenOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_dados = 'https://github.com/FabioPojo1987/FabioPojo1987-MVP_2_DATA_SCIENCE_PUC_RIO/blob/main/Google_Stock_Train%20(2010-2022).csv'"
      ],
      "metadata": {
        "id": "bKUxP8hIceVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importar os dados\n",
        "dataset_train = pd.read_csv(url_dados)\n",
        "training_set = dataset_train.iloc[:, 1:2].values # separar apenas os atributos\n",
        "# que usaremos no modelo"
      ],
      "metadata": {
        "id": "z22W9YeNcUw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_training_complete = pd.read_csv(\"/kaggle/input/google-stock-2010-2023/Google_Stock_Train (2010-2023).csv\")\n",
        "\n",
        "# Convert 'Date' column to datetime format\n",
        "google_training_complete['Date'] = pd.to_datetime(google_training_complete['Date'])\n",
        "\n",
        "google_training_complete.head(10)"
      ],
      "metadata": {
        "id": "l-h755C5gYRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desenhando gráfico em linhas dos valores de ação do Google no decorrer do tempo\n",
        "fig1 = px.line(google_training_complete, x='Date', y='Close', title='Valores de ação do Google no decorrer do tempo')\n",
        "fig1.show()"
      ],
      "metadata": {
        "id": "JV57w6fWgnoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo o volume do valor diário das ações\n",
        "fig2 = px.scatter(google_training_complete, x='Date', y='Volume', title='Volume do Valor Diário das ações')\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "dWWTU2eyhEhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformação\n",
        "from sklearn.preprocessing import MinMaxScaler # para colocar os valores numa mesma escala\n",
        "sc = MinMaxScaler(feature_range = (0, 1)) # a escala de normalização deve ser entre 0 e 1\n",
        "training_set_scaled = sc.fit_transform(training_set) # Escala para aplicar os dados no ato da normalização"
      ],
      "metadata": {
        "id": "ioeyGxldYVWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estruturas de dados com 60 intervalos de tempo, devemos usar\n",
        "# sempre 60 dias para poder fazer previsão da proxima saida\n",
        "X_train = [] # Criando a lista do Python para coletar dados desses 60 dias\n",
        "y_train = [] # Definindo a lista de previsão para o proximo dia\n",
        "for i in range(60, 1258):\n",
        "    X_train.append(training_set_scaled[i-60:i, 0])\n",
        "    y_train.append(training_set_scaled[i, 0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "metadata": {
        "id": "Ug0NqMppZvlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nesta etapa, serão organizados os dados de acordo com os formatos que são exigidos pelo Keras.\n",
        "#E,para que o Keras possa reconhecer, precisa estar conforme os seguintes parâmetros\n",
        "# batch_size, timesteps (para definição dos intervalos de treinamento, e quantitativos de indicadores a serem usados)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "4XksYAQ-Yumf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Para usar o Keras, é necessário importar as bibliotecas do Keras abaixo:\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout"
      ],
      "metadata": {
        "id": "sBXFRaAAYrnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nesta parte, devemos colocar os parâmetros necessários para podermos inicializar a rede neural\n",
        "regressor = Sequential()\n",
        "#A seguir, devemos criar as camadas\n",
        "#1\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "#2\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "#3\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "#4\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "# camada de saída (output)\n",
        "regressor.add(Dense(units = 1))"
      ],
      "metadata": {
        "id": "UGJnaK8fYndt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Após definir a rede neural, devemos compilar a rede\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "# Em seguida, definiremos os parâmetros de treinamento\n",
        "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
      ],
      "metadata": {
        "id": "vcRKb68FYiuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_dados2 = 'https://github.com/FabioPojo1987/FabioPojo1987-MVP_2_DATA_SCIENCE_PUC_RIO/blob/main/Google_Stock_Train%20(2010-2022).csv'"
      ],
      "metadata": {
        "id": "SyyQBBlzYVMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definir o Dataset para obter os dados reais\n",
        "dataset_test = pd.read_csv(url_dados2)\n",
        "real_stock_price = dataset_test.iloc[:, 1:2].values # Esse comando é para pegar apenas a coluna de saída (Open)"
      ],
      "metadata": {
        "id": "hDOPpgzKYU8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Para obter os dados de previsão\n",
        "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
        "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "inputs = inputs.reshape(-1,1) # deve usar esse comando para definir a variável passando entre -1 e 1 como parâmetro\n",
        "inputs = sc.transform(inputs) # este comando serve para gerar a normalização dos dados\n",
        "X_test = []\n",
        "for i in range(60, 80):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "predicted_stock_price = regressor.predict(X_test)\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "metadata": {
        "id": "vxsza4-ZYPYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerando a Visualizção dos Resultados\n",
        "plt.plot(real_stock_price, color = 'red', label = 'Valores reais das Ações do Google')\n",
        "plt.plot(predicted_stock_price, color = 'blue', label = 'Valores previstos das Ações do Google')\n",
        "plt.title('Previsão de Preços de Ações')\n",
        "plt.xlabel('Tempo')\n",
        "plt.ylabel('Preços de Ações do Google')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-fBsqmdvCu_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir deste trabalho, foi possível observar que o sistema de previsão até que conseguiu obter uma tendência bem interessante, especialmente sendo para pessoas que lidam com o mercado de ações na Bolsa de Valores.\n",
        "\n",
        "Contudo, ainda assim o algoritmo não conseguiu acertar as tendências. Errou em parte.\n",
        "\n",
        "Pois, utilizar esse tipo de metodologia (para tentar prever dados de ações financeiras) é algo bastante complexo e demanda muito tempo e poder de processamento para ter mais eficiência e precisão.\n",
        "\n",
        "Fora que, devido ao fato de se lidar com informações de risco, não é aconselhavel de se basear os investimentos de capital em modelos de simulação como esse.\n",
        "\n",
        "Porém, pode-se utilizar esse tipo de metodologia pra estudar e aprender novas possibilidades de previsões e de tendência."
      ],
      "metadata": {
        "id": "L6KmRbD2DIsd"
      }
    }
  ]
}