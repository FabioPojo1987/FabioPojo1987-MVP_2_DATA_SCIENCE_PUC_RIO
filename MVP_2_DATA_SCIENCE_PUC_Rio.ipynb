{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKCoUOtBjReGqhF69PPgx7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabioPojo1987/FabioPojo1987-MVP_2_DATA_SCIENCE_PUC_RIO/blob/main/MVP_2_DATA_SCIENCE_PUC_Rio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Projeto de MVP da 2ª Sprint do curso de Ciência de Dados na PUC-Rio (por Fabio Pojo de Almeida).**\n",
        "\n",
        "\n",
        "Este projeto se trata na construção de um modelo de aprendizado de máquina (\"machine learning\") para criar insights sobre como ocorre a variação de dados dos valores das ações do Google no Mercado de Ações.\n",
        "\n",
        "Onde foi utilizado um recorte temporal compreendido entre os anos de 2010 e 2023\n",
        "\n",
        "Este projeto está baseado em um modelo de \"Rede Neural Recorrente\" e está usando de referência os dados presentes nas planilhas csv\n",
        "\n",
        "Para isso, foi decidido um exemplo onde esses dados foram separados em duas bases em 2 arquivos diferentes: 1- base de treino e 2- teste (a faixa da base de teste tem como referência um período de 3 semanas, ou 21 dias)\n",
        "\n",
        "- A base de dados utilizada para os valores das ações do Google (Alphabet.inc.) foi obtida através do Kaggle em: https://www.kaggle.com/datasets/alirezajavid1999/google-stock-2010-2023/download?datasetVersionNumber=1\n",
        "\n",
        "\n",
        "Campos do dataset :\n",
        "\n",
        "1.   Date\n",
        "2.   Open - Valor das ações na Abertura\n",
        "3.   High - Valor mais alto do dia (\"Pico\")\n",
        "4.   Low - Valor mais baixo (\"vale\")\n",
        "5.   Volume - Volume a ser Negociado\n",
        "6.   High - Close : Valor (a maior) no momento de fechamento\n",
        "\n",
        "\n",
        "Objetivo - Usar os dados de treino para prever os valores que estão nos dados de teste, o objetivo é comparar a previsão do modelo com o que de fato aconteceu.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3uFgPvZiVsmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar as bibliotecas\n",
        "import numpy as np # vai ser usado pra criar os arrays\n",
        "!pip install pandas\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import plotly.express as px\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt # para gerar graficos\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.layers import GRU, Dropout, SimpleRNN, LSTM, Dense, SimpleRNN, GRU\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl1yGzrdenOH",
        "outputId": "92764077-fa35-4c0e-ffd4-f8b897370fdc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_dados = 'https://github.com/FabioPojo1987/FabioPojo1987-MVP_2_DATA_SCIENCE_PUC_RIO/blob/main/Google_Stock_Train%20(2010-2022).csv'"
      ],
      "metadata": {
        "id": "bKUxP8hIceVC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -I {url_dados}\n",
        "!head -n 1 {url_dados}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6zxnFY4pop5",
        "outputId": "d35c613a-eb0c-4426-f215-fbbe582d208f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `curl -I https://github.com/FabioPojo1987/FabioPojo1987-MVP_2_DATA_SCIENCE_PUC_RIO/blob/main/Google_Stock_Train%20(2010-2022).csv'\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `head -n 1 https://github.com/FabioPojo1987/FabioPojo1987-MVP_2_DATA_SCIENCE_PUC_RIO/blob/main/Google_Stock_Train%20(2010-2022).csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Neste passo devemos importar os dados\n",
        "dataset_train = pd.read_csv(url_dados)\n",
        "training_set = dataset_train.iloc[:, 1:2].values # para separar apenas os atributos\n",
        "# a serem usados no modelo"
      ],
      "metadata": {
        "id": "z22W9YeNcUw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_training_complete = pd.read_csv(\"Google_Stock_Train (2010-2023).csv\")\n",
        "\n",
        "# Convert 'Date' column to datetime format\n",
        "google_training_complete['Date'] = pd.to_datetime(google_training_complete['Date'])\n",
        "\n",
        "google_training_complete.head(10)"
      ],
      "metadata": {
        "id": "l-h755C5gYRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desenhando gráfico em linhas dos valores de ação do Google no decorrer do tempo\n",
        "fig1 = px.line(google_training_complete, x='Date', y='Close', title='Valores de ação do Google no decorrer do tempo')\n",
        "fig1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "JV57w6fWgnoa",
        "outputId": "ae3a3173-7366-43eb-b59e-6fc9ab812854"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'google_training_complete' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9edcc9e2d0b5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Desenhando gráfico em linhas dos valores de ação do Google no decorrer do tempo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoogle_training_complete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Valores de ação do Google no decorrer do tempo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfig1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'google_training_complete' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo o volume do valor diário das ações\n",
        "fig2 = px.scatter(google_training_complete, x='Date', y='Volume', title='Volume do Valor Diário das ações')\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "dWWTU2eyhEhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformação\n",
        "from sklearn.preprocessing import MinMaxScaler # para colocar os valores numa mesma escala\n",
        "sc = MinMaxScaler(feature_range = (0, 1)) # a escala de normalização deve ser entre 0 e 1\n",
        "training_set_scaled = sc.fit_transform(training_set) # Escala para aplicar os dados no ato da normalização"
      ],
      "metadata": {
        "id": "ioeyGxldYVWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estruturas de dados com 60 intervalos de tempo, devemos usar\n",
        "# sempre 60 dias para poder fazer previsão da proxima saida\n",
        "X_train = [] # Criando a lista do Python para coletar dados desses 60 dias\n",
        "y_train = [] # Definindo a lista de previsão para o proximo dia\n",
        "for i in range(60, 1258):\n",
        "    X_train.append(training_set_scaled[i-60:i, 0])\n",
        "    y_train.append(training_set_scaled[i, 0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "metadata": {
        "id": "Ug0NqMppZvlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nesta etapa, serão organizados os dados de acordo com os formatos que são exigidos pelo Keras.\n",
        "#E,para que o Keras possa reconhecer, precisa estar conforme os seguintes parâmetros\n",
        "# batch_size, timesteps (para definição dos intervalos de treinamento, e quantitativos de indicadores a serem usados)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "4XksYAQ-Yumf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Para usar o Keras, é necessário importar as bibliotecas do Keras abaixo:\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout"
      ],
      "metadata": {
        "id": "sBXFRaAAYrnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nesta parte, devemos colocar os parâmetros necessários para podermos inicializar a rede neural\n",
        "regressor = Sequential()\n",
        "#A seguir, devemos criar as camadas\n",
        "#1\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "#2\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "#3\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "#4\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "# camada de saída (output)\n",
        "regressor.add(Dense(units = 1))"
      ],
      "metadata": {
        "id": "UGJnaK8fYndt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Após definir a rede neural, devemos compilar a rede\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "# Em seguida, definiremos os parâmetros de treinamento\n",
        "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
      ],
      "metadata": {
        "id": "vcRKb68FYiuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_dados2 = 'https://github.com/FabioPojo1987/FabioPojo1987-MVP_2_DATA_SCIENCE_PUC_RIO/blob/main/Google_Stock_Train%20(2010-2022).csv'"
      ],
      "metadata": {
        "id": "SyyQBBlzYVMm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definir o Dataset para obter os dados reais\n",
        "dataset_test = pd.read_csv (url_dados2)\n",
        "real_stock_price = dataset_test.iloc[:, 1:2].values # Esse comando é para pegar apenas a coluna de saída (Open)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "hDOPpgzKYU8q",
        "outputId": "2d2c9380-f1e2-4050-efbf-4a56dd118042"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 1 fields in line 41, saw 16\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9ab04344dc1d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Definir o Dataset para obter os dados reais\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murl_dados2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mreal_stock_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;31m# Esse comando é para pegar apenas a coluna de saída (Open)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1702\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 41, saw 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Para obter os dados de previsão\n",
        "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
        "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "inputs = inputs.reshape(-1,1) # deve usar esse comando para definir a variável passando entre -1 e 1 como parâmetro\n",
        "inputs = sc.transform(inputs) # este comando serve para gerar a normalização dos dados\n",
        "X_test = []\n",
        "for i in range(60, 80):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "predicted_stock_price = regressor.predict(X_test)\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "metadata": {
        "id": "vxsza4-ZYPYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerando a Visualizção dos Resultados\n",
        "plt.plot(real_stock_price, color = 'red', label = 'Valores reais das Ações do Google')\n",
        "plt.plot(predicted_stock_price, color = 'blue', label = 'Valores previstos das Ações do Google')\n",
        "plt.title('Previsão de Preços de Ações')\n",
        "plt.xlabel('Tempo')\n",
        "plt.ylabel('Preços de Ações do Google')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-fBsqmdvCu_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir deste trabalho, foi possível observar que o sistema de previsão até que conseguiu obter uma tendência bem interessante, especialmente sendo para pessoas que lidam com o mercado de ações na Bolsa de Valores.\n",
        "\n",
        "Contudo, ainda assim o algoritmo não conseguiu acertar as tendências. Errou em parte.\n",
        "\n",
        "Pois, utilizar esse tipo de metodologia (para tentar prever dados de ações financeiras) é algo bastante complexo e demanda muito tempo e poder de processamento para ter mais eficiência e precisão.\n",
        "\n",
        "Fora que, devido ao fato de se lidar com informações de risco, não é aconselhavel de se basear os investimentos de capital em modelos de simulação como esse.\n",
        "\n",
        "Porém, pode-se utilizar esse tipo de metodologia pra estudar e aprender novas possibilidades de previsões e de tendência."
      ],
      "metadata": {
        "id": "L6KmRbD2DIsd"
      }
    }
  ]
}